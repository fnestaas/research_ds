# Research in Data Science
### Semester Project Fredrik Nestaas

See the report under **Documents and other work**.

This is the code for my semester project on NeuralODEs in the Spring of 2022. 
We started from existing research on exploding gradients in NeuralODEs and show that placing strict requirements on the norm of the adjoint in NeuralODEs leads to a small class of available functions that can be learned.
On the other hand, we analyze the mathematics of the NeuralODE adjoint and come up with an architecture that empirically has more stable adjoint behavior, but unfortunately requires too many function evaluations to be feasible for more stable training.



